{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad71c3a8-bc41-47c2-bfaa-4757cbceedf2",
   "metadata": {},
   "source": [
    "# Practicum: Modern Hopfield Network Spell Checking and Word Recommendation\n",
    "___\n",
    "In this practicum problem, we'll implement a modern Hopfield Network and use it for spell checking and word recommendation tasks.\n",
    "\n",
    "* _What are Hopfield Networks_? Hopfield Networks are used for associative memory, where the network can recall a pattern from a partial input. The modern version of Hopfield Networks uses continuous values instead of binary values, and it can store multiple patterns. \n",
    "* We'll use the following paper to guide our implementation and analysis: [Ramsauer, H., Schafl, B., Lehner, J., Seidl, P., Widrich, M., Gruber, L., Holzleitner, M., Pavlovi'c, M., Sandve, G.K., Greiff, V., Kreil, D.P., Kopp, M., Klambauer, G., Brandstetter, J., & Hochreiter, S. (2020). Hopfield Networks is All You Need. ArXiv, abs/2008.02217.](https://arxiv.org/abs/2008.02217)\n",
    "\n",
    "## Tasks\n",
    "Before we get started, we'll quickly review modern Hopfied Networks. Then, you'll execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants (5 min)__: Let's take 5 minutes to load [a Simpsons character library from Kaggle](https://www.kaggle.com/datasets/kostastokis/simpsons-faces) that our Hopfield network will memorize.\n",
    "*  __Task 2: Build a Modern Network Model (5 min)__: In this task, we'll formulate the image dataset we give the network and then create a model of a modern Hopfield network. We'll also quickly check to ensure we are doing what we think we are doing.\n",
    "* __Task 3: Retrieve a memory from the network (30 min)__: In this task, we will retrieve a memory from the modern Hopfield network starting from a random state vector $\\mathbf{s}_{\\circ}$. We'll corrupt an image (by cutting off some fraction of the image) and then see if the model recovers the correct memory given the corrupted starting point. \n",
    "\n",
    "Let's get started!\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e0a48",
   "metadata": {},
   "source": [
    "## Background\n",
    "A modern Hopfield network addresses many of the perceived limitations of the original Hopfield network. The original Hopfield network was limited to binary values and could only store a limited number of patterns. The modern Hopfield network uses continuous values and can store a large number of patterns.\n",
    "* For a detailed discussion of the key milestones in the development of modern Hopfield networks, check out [Hopfield Networks is All You Need Blog, GitHub.io](https://ml-jku.github.io/hopfield-layers/)\n",
    "\n",
    "### Algorithm\n",
    "The user provides a set of memory vectors $\\mathbf{X} = \\left\\{\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots, \\mathbf{x}_{m}\\right\\}$, where $\\mathbf{x}_{i} \\in \\mathbb{R}^{n}$ is a memory vector of size $n$ and $m$ is the number of memory vectors. Further, the user provides an initial _partial memory_ $\\mathbf{s}_{\\circ} \\in \\mathbb{R}^{n}$, which is a vector of size $n$ that is a partial version of one of the memory vectors and specifies the _temperature_ $\\beta$ of the system.\n",
    "\n",
    "__Initialize__ the network with the memory vectors $\\mathbf{X}$, and the inverse temperature $\\beta$. Set current state to the initial state $\\mathbf{s} \\gets \\mathbf{s}_{\\circ}$\n",
    "\n",
    "Until convergence __do__:\n",
    "   1. Compute the _current_ probability vector defined as $\\mathbf{p} = \\texttt{softmax}(\\beta\\cdot\\mathbf{X}^{\\top}\\mathbf{s})$ where $\\mathbf{s}$ is the _current_ state vector, and $\\mathbf{X}^{\\top}$ is the transpose of the memory matrix $\\mathbf{X}$.\n",
    "   2. Compute the _next_ state vector $\\mathbf{s}^{\\prime} = \\mathbf{X}\\mathbf{p}$ and the _next_ probability vector $\\mathbf{p}^{\\prime} = \\texttt{softmax}(\\beta\\cdot\\mathbf{X}^{\\top}\\mathbf{s}^{\\prime})$.\n",
    "   3. If $\\mathbf{p}^{\\prime}$ is _close_ to $\\mathbf{p}$ or we run out of iterations, then __stop__. For example, $\\lVert \\mathbf{p}^{\\prime} - \\mathbf{p}\\rVert_{2}^{2} \\leq \\epsilon$ for some small $\\epsilon > 0$.\n",
    "   4. Otherwise, update the state $\\mathbf{s} \\gets\\mathbf{s}^{\\prime}$, and __go back to__ step 1.\n",
    "\n",
    "   \n",
    "This algorithm is implemented in [the `recover(...)` method](src/Compute.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b935753",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184b2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Practicum-S2025`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Practicum-S2025/Project.toml`\n",
      "  \u001b[90m[336ed68f] \u001b[39m\u001b[92m+ CSV v0.10.15\u001b[39m\n",
      "  \u001b[90m[aaaa29a8] \u001b[39m\u001b[92m+ Clustering v0.15.8\u001b[39m\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.0\u001b[39m\n",
      "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.7.0\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.17.0\u001b[39m\n",
      "  \u001b[90m[033835bb] \u001b[39m\u001b[92m+ JLD2 v0.5.13\u001b[39m\n",
      "  \u001b[90m[872c559c] \u001b[39m\u001b[92m+ NNlib v0.9.30\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.40.13\u001b[39m\n",
      "  \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v2.4.0\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[24678dba] \u001b[39m\u001b[92m+ TSne v1.3.0\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[93m~ LinearAlgebra ⇒ v1.11.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[93m~ Random ⇒ v1.11.0\u001b[39m\n",
      "  \u001b[90m[8dfed614] \u001b[39m\u001b[93m~ Test ⇒ v1.11.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Practicum-S2025/Manifest.toml`\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.3.0\u001b[39m\n",
      "  \u001b[90m[66dad0bd] \u001b[39m\u001b[92m+ AliasTables v1.1.3\u001b[39m\n",
      "  \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v1.1.1\u001b[39m\n",
      "  \u001b[90m[d1d4a3ce] \u001b[39m\u001b[92m+ BitFlags v0.1.9\u001b[39m\n",
      "  \u001b[90m[336ed68f] \u001b[39m\u001b[92m+ CSV v0.10.15\u001b[39m\n",
      "  \u001b[90m[d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.25.1\u001b[39m\n",
      "  \u001b[90m[aaaa29a8] \u001b[39m\u001b[92m+ Clustering v0.15.8\u001b[39m\n",
      "  \u001b[90m[944b1d66] \u001b[39m\u001b[92m+ CodecZlib v0.7.8\u001b[39m\n",
      "  \u001b[90m[35d6a980] \u001b[39m\u001b[92m+ ColorSchemes v3.29.0\u001b[39m\n",
      "  \u001b[90m[3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.12.1\u001b[39m\n",
      "  \u001b[90m[c3611d14] \u001b[39m\u001b[92m+ ColorVectorSpace v0.11.0\u001b[39m\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.0\u001b[39m\n",
      "  \u001b[90m[34da2185] \u001b[39m\u001b[92m+ Compat v4.16.0\u001b[39m\n",
      "  \u001b[90m[f0e56b4a] \u001b[39m\u001b[92m+ ConcurrentUtilities v2.5.0\u001b[39m\n",
      "  \u001b[90m[d38c429a] \u001b[39m\u001b[92m+ Contour v0.6.3\u001b[39m\n",
      "  \u001b[90m[a8cc5b0e] \u001b[39m\u001b[92m+ Crayons v4.1.1\u001b[39m\n",
      "  \u001b[90m[9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.16.0\u001b[39m\n",
      "  \u001b[90m[a93c6f00] \u001b[39m\u001b[92m+ DataFrames v1.7.0\u001b[39m\n",
      "  \u001b[90m[864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.22\u001b[39m\n",
      "  \u001b[90m[e2d170a0] \u001b[39m\u001b[92m+ DataValueInterfaces v1.0.0\u001b[39m\n",
      "  \u001b[90m[8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles v1.9.1\u001b[39m\n",
      "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
      "  \u001b[90m[ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.9.4\u001b[39m\n",
      "  \u001b[90m[460bff9d] \u001b[39m\u001b[92m+ ExceptionUnwrapping v0.1.11\u001b[39m\n",
      "  \u001b[90m[c87230d0] \u001b[39m\u001b[92m+ FFMPEG v0.4.2\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.17.0\u001b[39m\n",
      "  \u001b[90m[48062228] \u001b[39m\u001b[92m+ FilePathsBase v0.9.24\u001b[39m\n",
      "  \u001b[90m[53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.5\u001b[39m\n",
      "  \u001b[90m[1fa38f19] \u001b[39m\u001b[92m+ Format v1.3.7\u001b[39m\n",
      "  \u001b[90m[46192b85] \u001b[39m\u001b[92m+ GPUArraysCore v0.2.0\u001b[39m\n",
      "  \u001b[90m[28b8d3ca] \u001b[39m\u001b[92m+ GR v0.73.14\u001b[39m\n",
      "  \u001b[90m[42e2da0e] \u001b[39m\u001b[92m+ Grisu v1.0.2\u001b[39m\n",
      "  \u001b[90m[cd3eb016] \u001b[39m\u001b[92m+ HTTP v1.10.16\u001b[39m\n",
      "  \u001b[90m[076d061b] \u001b[39m\u001b[92m+ HashArrayMappedTries v0.2.0\u001b[39m\n",
      "  \u001b[90m[842dd82b] \u001b[39m\u001b[92m+ InlineStrings v1.4.3\u001b[39m\n",
      "  \u001b[90m[41ab1584] \u001b[39m\u001b[92m+ InvertedIndices v1.3.1\u001b[39m\n",
      "  \u001b[90m[92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.2.4\u001b[39m\n",
      "  \u001b[90m[82899510] \u001b[39m\u001b[92m+ IteratorInterfaceExtensions v1.0.0\u001b[39m\n",
      "  \u001b[90m[033835bb] \u001b[39m\u001b[92m+ JLD2 v0.5.13\u001b[39m\n",
      "  \u001b[90m[1019f520] \u001b[39m\u001b[92m+ JLFzf v0.1.11\u001b[39m\n",
      "  \u001b[90m[692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.7.0\u001b[39m\n",
      "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
      "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.34\u001b[39m\n",
      "  \u001b[90m[b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.4.0\u001b[39m\n",
      "  \u001b[90m[23fbe1c1] \u001b[39m\u001b[92m+ Latexify v0.16.7\u001b[39m\n",
      "  \u001b[90m[2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.29\u001b[39m\n",
      "  \u001b[90m[e6f89c97] \u001b[39m\u001b[92m+ LoggingExtras v1.1.0\u001b[39m\n",
      "  \u001b[90m[1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.16\u001b[39m\n",
      "  \u001b[90m[739be429] \u001b[39m\u001b[92m+ MbedTLS v1.1.9\u001b[39m\n",
      "  \u001b[90m[442fdcdd] \u001b[39m\u001b[92m+ Measures v0.3.2\u001b[39m\n",
      "  \u001b[90m[e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.2.0\u001b[39m\n",
      "  \u001b[90m[872c559c] \u001b[39m\u001b[92m+ NNlib v0.9.30\u001b[39m\n",
      "  \u001b[90m[77ba4419] \u001b[39m\u001b[92m+ NaNMath v1.1.3\u001b[39m\n",
      "  \u001b[90m[b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.21\u001b[39m\n",
      "  \u001b[90m[4d8831e6] \u001b[39m\u001b[92m+ OpenSSL v1.4.3\u001b[39m\n",
      "  \u001b[90m[bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.8.0\u001b[39m\n",
      "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.3\u001b[39m\n",
      "  \u001b[90m[ccf2f8ad] \u001b[39m\u001b[92m+ PlotThemes v3.3.0\u001b[39m\n",
      "  \u001b[90m[995b91a9] \u001b[39m\u001b[92m+ PlotUtils v1.4.3\u001b[39m\n",
      "  \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.40.13\u001b[39m\n",
      "  \u001b[90m[2dfb63ee] \u001b[39m\u001b[92m+ PooledArrays v1.4.3\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.2.1\u001b[39m\n",
      "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.4.3\u001b[39m\n",
      "  \u001b[90m[08abe8d2] \u001b[39m\u001b[92m+ PrettyTables v2.4.0\u001b[39m\n",
      "  \u001b[90m[92933f4c] \u001b[39m\u001b[92m+ ProgressMeter v1.10.4\u001b[39m\n",
      "  \u001b[90m[43287f4e] \u001b[39m\u001b[92m+ PtrArrays v1.3.0\u001b[39m\n",
      "  \u001b[90m[3cdcf5f2] \u001b[39m\u001b[92m+ RecipesBase v1.3.4\u001b[39m\n",
      "  \u001b[90m[01d81517] \u001b[39m\u001b[92m+ RecipesPipeline v0.6.12\u001b[39m\n",
      "  \u001b[90m[189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
      "  \u001b[90m[05181044] \u001b[39m\u001b[92m+ RelocatableFolders v1.0.1\u001b[39m\n",
      "  \u001b[90m[ae029012] \u001b[39m\u001b[92m+ Requires v1.3.1\u001b[39m\n",
      "  \u001b[90m[7e506255] \u001b[39m\u001b[92m+ ScopedValues v1.3.0\u001b[39m\n",
      "  \u001b[90m[6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.2.1\u001b[39m\n",
      "  \u001b[90m[91c51154] \u001b[39m\u001b[92m+ SentinelArrays v1.4.8\u001b[39m\n",
      "  \u001b[90m[992d4aef] \u001b[39m\u001b[92m+ Showoff v1.0.3\u001b[39m\n",
      "  \u001b[90m[777ac1f9] \u001b[39m\u001b[92m+ SimpleBufferStream v1.2.0\u001b[39m\n",
      "  \u001b[90m[a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.2.1\u001b[39m\n",
      "  \u001b[90m[860ef19b] \u001b[39m\u001b[92m+ StableRNGs v1.0.2\u001b[39m\n",
      "  \u001b[90m[90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.13\u001b[39m\n",
      "  \u001b[90m[1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.3\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[82ae8749] \u001b[39m\u001b[92m+ StatsAPI v1.7.0\u001b[39m\n",
      "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.4\u001b[39m\n",
      "  \u001b[90m[892a3eda] \u001b[39m\u001b[92m+ StringManipulation v0.4.1\u001b[39m\n",
      "  \u001b[90m[24678dba] \u001b[39m\u001b[92m+ TSne v1.3.0\u001b[39m\n",
      "  \u001b[90m[3783bdb8] \u001b[39m\u001b[92m+ TableTraits v1.0.1\u001b[39m\n",
      "  \u001b[90m[bd369af6] \u001b[39m\u001b[92m+ Tables v1.12.0\u001b[39m\n",
      "  \u001b[90m[62fd8b95] \u001b[39m\u001b[92m+ TensorCore v0.1.1\u001b[39m\n",
      "  \u001b[90m[3bb67fe8] \u001b[39m\u001b[92m+ TranscodingStreams v0.11.3\u001b[39m\n",
      "  \u001b[90m[5c2747f8] \u001b[39m\u001b[92m+ URIs v1.5.2\u001b[39m\n",
      "  \u001b[90m[1cfade01] \u001b[39m\u001b[92m+ UnicodeFun v0.4.1\u001b[39m\n",
      "  \u001b[90m[1986cc42] \u001b[39m\u001b[92m+ Unitful v1.22.0\u001b[39m\n",
      "  \u001b[90m[45397f5d] \u001b[39m\u001b[92m+ UnitfulLatexify v1.6.4\u001b[39m\n",
      "  \u001b[90m[013be700] \u001b[39m\u001b[92m+ UnsafeAtomics v0.3.0\u001b[39m\n",
      "  \u001b[90m[41fe7b60] \u001b[39m\u001b[92m+ Unzip v0.2.0\u001b[39m\n",
      "  \u001b[90m[ea10d353] \u001b[39m\u001b[92m+ WeakRefStrings v1.4.2\u001b[39m\n",
      "  \u001b[90m[76eceee3] \u001b[39m\u001b[92m+ WorkerUtilities v1.6.1\u001b[39m\n",
      "  \u001b[90m[6e34b625] \u001b[39m\u001b[92m+ Bzip2_jll v1.0.9+0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[83423d85] \u001b[39m\u001b[92m+ Cairo_jll v1.18.4+0\u001b[39m\n",
      "  \u001b[90m[ee1fde0b] \u001b[39m\u001b[92m+ Dbus_jll v1.16.2+0\u001b[39m\n",
      "  \u001b[90m[2702e6a9] \u001b[39m\u001b[92m+ EpollShim_jll v0.0.20230411+1\u001b[39m\n",
      "  \u001b[90m[2e619515] \u001b[39m\u001b[92m+ Expat_jll v2.6.5+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[b22a6f82] \u001b[39m\u001b[92m+ FFMPEG_jll v4.4.4+1\u001b[39m\n",
      "  \u001b[90m[a3f928ae] \u001b[39m\u001b[92m+ Fontconfig_jll v2.16.0+0\u001b[39m\n",
      "  \u001b[90m[d7e528f0] \u001b[39m\u001b[92m+ FreeType2_jll v2.13.4+0\u001b[39m\n",
      "  \u001b[90m[559328eb] \u001b[39m\u001b[92m+ FriBidi_jll v1.0.17+0\u001b[39m\n",
      "  \u001b[90m[0656b61e] \u001b[39m\u001b[92m+ GLFW_jll v3.4.0+2\u001b[39m\n",
      "  \u001b[90m[d2c73de3] \u001b[39m\u001b[92m+ GR_jll v0.73.14+0\u001b[39m\n",
      "  \u001b[90m[78b55507] \u001b[39m\u001b[92m+ Gettext_jll v0.21.0+0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[7746bdde] \u001b[39m\u001b[92m+ Glib_jll v2.82.4+0\u001b[39m\n",
      "  \u001b[90m[3b182d85] \u001b[39m\u001b[92m+ Graphite2_jll v1.3.15+0\u001b[39m\n",
      "  \u001b[90m[2e76f6c2] \u001b[39m\u001b[92m+ HarfBuzz_jll v8.5.0+0\u001b[39m\n",
      "  \u001b[90m[aacddb02] \u001b[39m\u001b[92m+ JpegTurbo_jll v3.1.1+0\u001b[39m\n",
      "  \u001b[90m[c1c5ebd0] \u001b[39m\u001b[92m+ LAME_jll v3.100.2+0\u001b[39m\n",
      "  \u001b[90m[88015f11] \u001b[39m\u001b[92m+ LERC_jll v4.0.1+0\u001b[39m\n",
      "  \u001b[90m[1d63c593] \u001b[39m\u001b[92m+ LLVMOpenMP_jll v18.1.8+0\u001b[39m\n",
      "  \u001b[90m[dd4b983a] \u001b[39m\u001b[92m+ LZO_jll v2.10.3+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[e9f186c6] \u001b[39m\u001b[92m+ Libffi_jll v3.2.2+2\u001b[39m\n",
      "  \u001b[90m[7e76a0d4] \u001b[39m\u001b[92m+ Libglvnd_jll v1.7.1+1\u001b[39m\n",
      "  \u001b[90m[94ce4f54] \u001b[39m\u001b[92m+ Libiconv_jll v1.18.0+0\u001b[39m\n",
      "  \u001b[90m[4b2f31a3] \u001b[39m\u001b[92m+ Libmount_jll v2.41.0+0\u001b[39m\n",
      "  \u001b[90m[89763e89] \u001b[39m\u001b[92m+ Libtiff_jll v4.7.1+0\u001b[39m\n",
      "  \u001b[90m[38a345b3] \u001b[39m\u001b[92m+ Libuuid_jll v2.41.0+0\u001b[39m\n",
      "  \u001b[90m[e7412a2a] \u001b[39m\u001b[92m+ Ogg_jll v1.3.5+1\u001b[39m\n",
      "  \u001b[90m[458c3c95] \u001b[39m\u001b[92m+ OpenSSL_jll v3.5.0+0\u001b[39m\n",
      "  \u001b[90m[91d4177d] \u001b[39m\u001b[92m+ Opus_jll v1.3.3+0\u001b[39m\n",
      "  \u001b[90m[36c8627f] \u001b[39m\u001b[92m+ Pango_jll v1.56.1+0\u001b[39m\n",
      "  \u001b[90m[30392449] \u001b[39m\u001b[92m+ Pixman_jll v0.44.2+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[c0090381] \u001b[39m\u001b[92m+ Qt6Base_jll v6.7.1+1\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[629bc702] \u001b[39m\u001b[92m+ Qt6Declarative_jll v6.7.1+2\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[ce943373] \u001b[39m\u001b[92m+ Qt6ShaderTools_jll v6.7.1+1\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[e99dba38] \u001b[39m\u001b[92m+ Qt6Wayland_jll v6.7.1+1\u001b[39m\n",
      "  \u001b[90m[a44049a8] \u001b[39m\u001b[92m+ Vulkan_Loader_jll v1.3.243+0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[a2964d1f] \u001b[39m\u001b[92m+ Wayland_jll v1.21.0+2\u001b[39m\n",
      "  \u001b[90m[2381bf8a] \u001b[39m\u001b[92m+ Wayland_protocols_jll v1.36.0+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[02c8fc9c] \u001b[39m\u001b[92m+ XML2_jll v2.13.6+1\u001b[39m\n",
      "  \u001b[90m[ffd25f8a] \u001b[39m\u001b[92m+ XZ_jll v5.8.1+0\u001b[39m\n",
      "  \u001b[90m[f67eecfb] \u001b[39m\u001b[92m+ Xorg_libICE_jll v1.1.2+0\u001b[39m\n",
      "  \u001b[90m[c834827a] \u001b[39m\u001b[92m+ Xorg_libSM_jll v1.2.6+0\u001b[39m\n",
      "  \u001b[90m[4f6342f7] \u001b[39m\u001b[92m+ Xorg_libX11_jll v1.8.12+0\u001b[39m\n",
      "  \u001b[90m[0c0b7dd1] \u001b[39m\u001b[92m+ Xorg_libXau_jll v1.0.13+0\u001b[39m\n",
      "  \u001b[90m[935fb764] \u001b[39m\u001b[92m+ Xorg_libXcursor_jll v1.2.4+0\u001b[39m\n",
      "  \u001b[90m[a3789734] \u001b[39m\u001b[92m+ Xorg_libXdmcp_jll v1.1.6+0\u001b[39m\n",
      "  \u001b[90m[1082639a] \u001b[39m\u001b[92m+ Xorg_libXext_jll v1.3.7+0\u001b[39m\n",
      "  \u001b[90m[d091e8ba] \u001b[39m\u001b[92m+ Xorg_libXfixes_jll v6.0.1+0\u001b[39m\n",
      "  \u001b[90m[a51aa0fd] \u001b[39m\u001b[92m+ Xorg_libXi_jll v1.8.3+0\u001b[39m\n",
      "  \u001b[90m[d1454406] \u001b[39m\u001b[92m+ Xorg_libXinerama_jll v1.1.6+0\u001b[39m\n",
      "  \u001b[90m[ec84b674] \u001b[39m\u001b[92m+ Xorg_libXrandr_jll v1.5.5+0\u001b[39m\n",
      "  \u001b[90m[ea2f1a96] \u001b[39m\u001b[92m+ Xorg_libXrender_jll v0.9.12+0\u001b[39m\n",
      "  \u001b[90m[c7cfdc94] \u001b[39m\u001b[92m+ Xorg_libxcb_jll v1.17.1+0\u001b[39m\n",
      "  \u001b[90m[cc61e674] \u001b[39m\u001b[92m+ Xorg_libxkbfile_jll v1.1.3+0\u001b[39m\n",
      "  \u001b[90m[e920d4aa] \u001b[39m\u001b[92m+ Xorg_xcb_util_cursor_jll v0.1.4+0\u001b[39m\n",
      "  \u001b[90m[12413925] \u001b[39m\u001b[92m+ Xorg_xcb_util_image_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[2def613f] \u001b[39m\u001b[92m+ Xorg_xcb_util_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[975044d2] \u001b[39m\u001b[92m+ Xorg_xcb_util_keysyms_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[0d47668e] \u001b[39m\u001b[92m+ Xorg_xcb_util_renderutil_jll v0.3.9+1\u001b[39m\n",
      "  \u001b[90m[c22f9ab0] \u001b[39m\u001b[92m+ Xorg_xcb_util_wm_jll v0.4.1+1\u001b[39m\n",
      "  \u001b[90m[35661453] \u001b[39m\u001b[92m+ Xorg_xkbcomp_jll v1.4.7+0\u001b[39m\n",
      "  \u001b[90m[33bec58e] \u001b[39m\u001b[92m+ Xorg_xkeyboard_config_jll v2.44.0+0\u001b[39m\n",
      "  \u001b[90m[c5fb5394] \u001b[39m\u001b[92m+ Xorg_xtrans_jll v1.6.0+0\u001b[39m\n",
      "  \u001b[90m[3161d3a3] \u001b[39m\u001b[92m+ Zstd_jll v1.5.7+1\u001b[39m\n",
      "  \u001b[90m[35ca27e7] \u001b[39m\u001b[92m+ eudev_jll v3.2.9+0\u001b[39m\n",
      "  \u001b[90m[214eeab7] \u001b[39m\u001b[92m+ fzf_jll v0.61.1+0\u001b[39m\n",
      "  \u001b[90m[1a1c6b14] \u001b[39m\u001b[92m+ gperf_jll v3.1.1+1\u001b[39m\n",
      "  \u001b[90m[a4ae2306] \u001b[39m\u001b[92m+ libaom_jll v3.11.0+0\u001b[39m\n",
      "  \u001b[90m[0ac62f75] \u001b[39m\u001b[92m+ libass_jll v0.15.2+0\u001b[39m\n",
      "  \u001b[90m[1183f4f0] \u001b[39m\u001b[92m+ libdecor_jll v0.2.2+0\u001b[39m\n",
      "  \u001b[90m[2db6ffa8] \u001b[39m\u001b[92m+ libevdev_jll v1.11.0+0\u001b[39m\n",
      "  \u001b[90m[f638f0a6] \u001b[39m\u001b[92m+ libfdk_aac_jll v2.0.3+0\u001b[39m\n",
      "  \u001b[90m[36db933b] \u001b[39m\u001b[92m+ libinput_jll v1.18.0+0\u001b[39m\n",
      "  \u001b[90m[b53b4c65] \u001b[39m\u001b[92m+ libpng_jll v1.6.47+0\u001b[39m\n",
      "  \u001b[90m[f27f6e37] \u001b[39m\u001b[92m+ libvorbis_jll v1.3.7+2\u001b[39m\n",
      "  \u001b[90m[009596ad] \u001b[39m\u001b[92m+ mtdev_jll v1.1.6+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[1270edf5] \u001b[39m\u001b[92m+ x264_jll v2021.5.5+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[dfaa095f] \u001b[39m\u001b[92m+ x265_jll v3.5.0+0\u001b[39m\n",
      "  \u001b[90m[d8fb68d0] \u001b[39m\u001b[92m+ xkbcommon_jll v1.8.1+0\u001b[39m\n",
      "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.2\u001b[39m\n",
      "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64 v1.11.0\u001b[39m\n",
      "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates v1.11.0\u001b[39m\n",
      "  \u001b[90m[8ba89e20] \u001b[39m\u001b[92m+ Distributed v1.11.0\u001b[39m\n",
      "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
      "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching v1.11.0\u001b[39m\n",
      "  \u001b[90m[9fa8497b] \u001b[39m\u001b[92m+ Future v1.11.0\u001b[39m\n",
      "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils v1.11.0\u001b[39m\n",
      "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
      "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2 v1.11.0\u001b[39m\n",
      "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl v1.11.0\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra v1.11.0\u001b[39m\n",
      "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging v1.11.0\u001b[39m\n",
      "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown v1.11.0\u001b[39m\n",
      "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap v1.11.0\u001b[39m\n",
      "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
      "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.11.0\u001b[39m\n",
      "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf v1.11.0\u001b[39m\n",
      "  \u001b[90m[3fa0cd96] \u001b[39m\u001b[92m+ REPL v1.11.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random v1.11.0\u001b[39m\n",
      "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization v1.11.0\u001b[39m\n",
      "  \u001b[90m[6462fe0b] \u001b[39m\u001b[92m+ Sockets v1.11.0\u001b[39m\n",
      "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays v1.11.0\u001b[39m\n",
      "  \u001b[90m[f489334b] \u001b[39m\u001b[92m+ StyledStrings v1.11.0\u001b[39m\n",
      "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
      "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
      "  \u001b[90m[8dfed614] \u001b[39m\u001b[92m+ Test v1.11.0\u001b[39m\n",
      "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs v1.11.0\u001b[39m\n",
      "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode v1.11.0\u001b[39m\n",
      "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.1.1+0\u001b[39m\n",
      "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.6.0+0\u001b[39m\n",
      "  \u001b[90m[e37daf67] \u001b[39m\u001b[92m+ LibGit2_jll v1.7.2+0\u001b[39m\n",
      "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.0+1\u001b[39m\n",
      "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.6+0\u001b[39m\n",
      "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2023.12.12\u001b[39m\n",
      "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.27+1\u001b[39m\n",
      "  \u001b[90m[05823500] \u001b[39m\u001b[92m+ OpenLibm_jll v0.8.5+0\u001b[39m\n",
      "  \u001b[90m[efcefdf7] \u001b[39m\u001b[92m+ PCRE2_jll v10.42.0+1\u001b[39m\n",
      "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v7.7.0+0\u001b[39m\n",
      "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.13+1\u001b[39m\n",
      "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.11.0+0\u001b[39m\n",
      "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.59.0+0\u001b[39m\n",
      "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.4.0+2\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Practicum-S2025/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Practicum-S2025/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\"); # load a bunch of libs, including the ones we need to work with images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aba20e",
   "metadata": {},
   "source": [
    "### Constants\n",
    "Before we load the data, let's set up some constants that we will use in the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f255b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words_to_memorize = 24; # how many images do we want to memorize?\n",
    "number_of_embedding_dimesions = 50; # number of embedding dimensions for each word\n",
    "β = 0.5; # Inverse temperature of the system (high T -> low β)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99cc6c7",
   "metadata": {},
   "source": [
    "### Data\n",
    "We'll use the [GloVe pretrained word embedding dataset](https://nlp.stanford.edu/projects/glove/) to as the memories for our Hopfield model. The **GloVe (Global Vectors for Word Representation)** dataset is a widely used pre-trained word embedding resource developed by Pennington, Socher, and Manning at Stanford University. \n",
    "* _What is it?_ It constructs vector representations of words by aggregating global word co-occurrence statistics from a corpus, enabling semantic relationships to be captured in vector space. GloVe embeddings have been trained on large datasets such as Wikipedia, Gigaword, and Common Crawl, offering dimensionalities typically ranging from 50 to 300. These embeddings are foundational for many NLP tasks, including text classification, sentiment analysis, and machine translation.\n",
    "* See: [Pennington et al., EMNLP 2014, GloVe: Global Vectors for Word Representation](https://aclanthology.org/D14-1162/) for more details on this dataset.\n",
    "\n",
    "This dataset is large, so we won't check it into the repository. Instead, we'll download it from the internet. Fill me in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34627ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec, vec2word = let\n",
    "\n",
    "    # do we have the embeddings downloaded?\n",
    "    data = nothing;\n",
    "    if (isfile(joinpath(_PATH_TO_DATA, \"glove_6B_50d.jld2\")) == false) \n",
    "        # TODO: download logic goes here ...\n",
    "    else\n",
    "        data = JLD2.load(joinpath(_PATH_TO_DATA, \"glove_6B_50d.jld2\")) # Ok, we have the embeddings file, so let's load it\n",
    "    end\n",
    "\n",
    "    # load the embeddings\n",
    "    word2vec = data[\"word2vec\"] # this is a Dict{String, Tuple{Float32}}\n",
    "    vec2word = data[\"vec2word\"] # this is a Dict{Tuple{Float32}, String}\n",
    "\n",
    "    # return -\n",
    "    (word2vec, vec2word)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b6cd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, NTuple{50, Float64}} with 400000 entries:\n",
       "  \"newdigate\"   => (-0.13302, 0.99457, 0.19927, 0.062554, 0.40293, 0.58369, 0.1…\n",
       "  \"daufuskie\"   => (0.47702, -0.33101, -1.0066, 0.70388, -0.29973, -0.54381, -0…\n",
       "  \"single-arm\"  => (0.7153, 0.67314, 1.6732, 0.21066, 1.1875, 2.3162, 0.078471,…\n",
       "  \"titration\"   => (0.30649, -0.66054, -0.27341, -0.30447, -0.58893, 0.64415, 1…\n",
       "  \"qajar\"       => (-1.2141, -0.039392, -0.63721, 0.058088, -0.22625, -1.0897, …\n",
       "  \"pinheiro\"    => (0.49711, -0.31449, -1.0776, 0.61769, 0.066749, -2.1997, 0.0…\n",
       "  \"hospitalet\"  => (-0.55697, 0.19924, -1.099, -0.92013, -1.1645, -0.45907, 0.7…\n",
       "  \"kennedale\"   => (-0.91243, -0.097526, 0.031527, 0.71883, -0.89733, -1.0061, …\n",
       "  \"tetracyclic\" => (0.49991, -0.98145, 0.01992, -0.88848, 0.24377, 0.27405, 0.8…\n",
       "  \"moher\"       => (0.097974, 0.99096, -0.63521, 0.49702, 0.043669, 0.035202, 0…\n",
       "  \"entomb\"      => (0.64585, -0.28799, 0.59975, -0.43203, -0.64485, 0.11591, -0…\n",
       "  \"vanderwerff\" => (-1.0542, -0.47031, -1.4568, 0.93613, 0.062686, 1.5889, -0.6…\n",
       "  \"whiz\"        => (-0.93844, -0.15695, 1.0516, -0.47339, -0.58016, -0.85521, -…\n",
       "  \"hi5\"         => (0.23578, -0.045139, 0.79017, 0.23509, -0.68271, 0.39011, -0…\n",
       "  \"johnswort\"   => (0.75264, 0.51297, -0.093784, -1.1576, -0.018352, -0.91108, …\n",
       "  \"11-storey\"   => (0.036837, -0.076804, 0.6941, -0.92608, 1.4386, -0.078356, 0…\n",
       "  \"clapboards\"  => (-0.73615, 0.068203, 0.28849, -0.44785, -0.96452, 0.87112, -…\n",
       "  \"saïd\"        => (-1.3314, -0.13012, 0.37243, -0.18406, -0.056918, -1.2969, 0…\n",
       "  \"nóg\"         => (-0.88271, -0.35731, 0.3633, 0.45749, -1.5215, -0.14872, 1.1…\n",
       "  ⋮             => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221159d",
   "metadata": {},
   "source": [
    "Fill me in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c94374",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words, test_vocabulary = let\n",
    "\n",
    "    # initialize -\n",
    "    vocabulary = Array{Float64,2}(undef, number_of_words_to_memorize, number_of_embedding_dimesions); # this is a matrix of Float64\n",
    "    test_words = Array{String,1}(undef, number_of_words_to_memorize); # this is a vector of strings\n",
    "    total_number_of_words = length(word2vec); # this is the total number of words in the dataset\n",
    "    index_of_words_to_learn = randperm(total_number_of_words)[1:number_of_words_to_memorize]; # this is the random index of words to learn\n",
    "\n",
    "    # get the keys of word2vec -\n",
    "    words = keys(word2vec) |> collect; # this is a vector of strings\n",
    "\n",
    "    # loop over the words to learn\n",
    "    for i ∈ eachindex(index_of_words_to_learn)\n",
    "        \n",
    "        j = index_of_words_to_learn[i]; # this is the index of the word we want to learn\n",
    "        wⱼ = words[j]; # this is the word we want to learn\n",
    "        test_words[i] = wⱼ; # this is the word we want to learn \n",
    "        embedding = word2vec[wⱼ]; # this is the embedding of the word we want to learn\n",
    "\n",
    "        for j ∈ 1:number_of_embedding_dimesions\n",
    "            vocabulary[i,j] = embedding[j]; # this is the embedding of the word we want to learn\n",
    "        end\n",
    "    end\n",
    "\n",
    "    test_vocabulary = vocabulary |> transpose |> Matrix; # this is the vocabulary we want to learn\n",
    "\n",
    "    # return -\n",
    "    (test_words, test_vocabulary);\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc729cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24-element Vector{String}:\n",
       " \"klingenthal\"\n",
       " \"riedelsheimer\"\n",
       " \"newpaper\"\n",
       " \"vixen\"\n",
       " \"botticelli\"\n",
       " \"mtbe\"\n",
       " \"bodian\"\n",
       " \"thiocyanate\"\n",
       " \"riles\"\n",
       " \"strad\"\n",
       " ⋮\n",
       " \"klitschkos\"\n",
       " \"dustup\"\n",
       " \"activités\"\n",
       " \"rybarikova\"\n",
       " \"2125\"\n",
       " \"sippola\"\n",
       " \"3634\"\n",
       " \"arimori\"\n",
       " \"58-58\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccd492",
   "metadata": {},
   "source": [
    "__Let's do some fun stuff with embeddings.__ Fill me in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ddd93",
   "metadata": {},
   "source": [
    "## Task 2: Can we recover an uncorrupted memory?\n",
    "In this task, we'll formulate the set of word embeddings (memories) that we feed to a modern Hopfield network. First, we'll create a modern Hopfield network model, and then we'll use the model to retrieve a memory from the network. We'll do this by starting from a random state vector $\\mathbf{s}_{\\circ}$, which is a partial version of one of the memory vectors, i.e., a misspled word. We'll corrupt the word by randomly permuating it's embeddings, and then we'll see if the model recovers the correct word (memory) given the corrupted starting point.\n",
    "\n",
    "### Model\n",
    "Let's start by creating a model of a modern Hopfield network. \n",
    "* We'll construct [a `MyModernHopfieldNetworkModel` instance](src/Types.jl) using a custom [`build(...)` function](src/Factory.jl). The [`build(...)` method](src/Factory.jl) takes the type of thing we want to build, the (linearized) image library we want to encode, and the (inverse) system temperature $\\beta$ as inputs — images along the columns.\n",
    "* The [`build(...)` function](src/Factory.jl) returns a `MyModernHopfieldNetworkModel` instance, where the image library is stored in the `X::Array{Float64,2}` field, and the system temperature is stored in the `β::Float64` field.\n",
    "\n",
    "We'll store the Hopfield network instance in the `mymodel::MyModernHopfieldNetworkModel` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b88f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = let\n",
    "\n",
    "    # initialize -\n",
    "    memorycollection =test_vocabulary; # words (memories) on columns\n",
    "    index_vector = 1:number_of_words_to_memorize |> collect; # this is the index of the words we want to learn\n",
    "    words = keys(test_vocabulary) |> collect; # this is a vector of strings\n",
    "    \n",
    "    # build model -\n",
    "    model = build(MyModernHopfieldNetworkModel, (\n",
    "            memories = memorycollection, # this is the data we want to memorize. Images on columns\n",
    "            β = β, # Inverse temperature of the system. A big beta means we are more likely to get the right answer\n",
    "    ));\n",
    "\n",
    "    model; # return the model to the calling scope\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b18b75",
   "metadata": {},
   "source": [
    "__Check__: Let's do a quick check to make sure we are doing what we think we are doing. Let's check what's stored in the columns of the `model.X` field. These should be the words that we are encoding into the Hopfield network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8905f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word at index 18 that we encoded is: activités. The word from vec2word is: activités\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    \n",
    "    X = mymodel.X; # get the training data in the model\n",
    "    index_to_check = rand(1:number_of_words_to_memorize); # what index do we want to check?\n",
    "    \n",
    "    \n",
    "    eᵢ = X[:,index_to_check] |> Tuple # this is the embedding of the word we want to learn\n",
    "    wᵢ = test_words[index_to_check]; # this is the word we want to learn\n",
    "    ŵᵢ = vec2word[eᵢ]; # this is the word we think we learned\n",
    "\n",
    "    println(\"The word at index $(index_to_check) that we encoded is: $(wᵢ). The word from vec2word is: \", ŵᵢ);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cf809",
   "metadata": {},
   "source": [
    "### Retrieve a memory from the network\n",
    "Next, we'll test if we can recover uncorrupted and corrupted memories from the Hopfield network.\n",
    "\n",
    "* _What should we expect_: We are _guaranteed_ that the network will converge to a local minimum, but we are not guaranteed that the local minimum is the same as the original image. \n",
    "\n",
    "Let's start by specifying which memory we are trying to recover in the `memoryindextorecover::Int` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93d68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryindextorecover = 15; # which memory vector will we choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac193276",
   "metadata": {},
   "source": [
    "Next, let's build an uncorrupted and corrupted initial condition vector using the true word emebedding vector. We'll store \n",
    "the uncorrupted word in the `sₒ::Array{Float64,1}` variable, while the corrupted word will be stored in the `s₁::Array{Float64,1}` variable. Let's start with the uncorrupted memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5184ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sₒ = mymodel.X[:,memoryindextorecover]; # this is the memory vector we want to recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92773242",
   "metadata": {},
   "source": [
    "What word does `memoryindextorecover::Int64` point to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac7067c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word at index 15 that we (think) we encoded is: chikka. Check: the true word is: chikka\n"
     ]
    }
   ],
   "source": [
    "let \n",
    "    X = mymodel.X; # get the training data in the model\n",
    "    p = β*(transpose(X) * sₒ) |> s-> NNlib.softmax(s) # this is the probability of the word we want to learn\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "    w = test_words[memoryindextorecover]; # this is the word we want to learn\n",
    "    println(\"The word at index $(memoryindextorecover) that we (think) we encoded is: $(ŵ). Check: the true word is: \", w);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558716a",
   "metadata": {},
   "source": [
    "Now that we have a starting memory encoded in the state vector $\\mathbf{s}_{\\circ}$, can we recover the original uncorrupted word? We are guaranteed an image, but maybe _not_ the correct one.\n",
    "* _Implementation_: We implemented the modern Hopfield recovery algorithm above in [the `recover(...)` method](src/Compute.jl). This method takes our `model::MyModernHopfieldNetworkModel` instance, the initial configuration vector `sₒ::Array{Int32,1}`, and the maximum number `maxiterations::Int64`, and iteration tolerance parameter `ϵ::Float64`. \n",
    "* [The `recover(...)` method](src/Compute.jl) returns the recovered image in the e`s₁::Array{Float32,1}` variable, the image at each iteration in the `f::Dict{Int, Array{Float32,2}}` dictionary, and the probability of the image at each iteration in the `p::Dict{Int, Array{Float32,2}}` variable. The frames and probability dictionaries are indexed from `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3049a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ŝₒ,fₒ,pₒ) = recover(mymodel, sₒ, maxiterations = 10000, ϵ = 1e-16); # iterate until we hit stop condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b18c41",
   "metadata": {},
   "source": [
    "How many iterations did it take to converge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d6ef339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations: 13\n"
     ]
    }
   ],
   "source": [
    "println(\"How many iterations: $(length(fₒ))\") # how many iterations did we need to converge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a404ed",
   "metadata": {},
   "source": [
    "Fill me in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29818778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"chikka\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recovered_word_uncorrupted = let \n",
    "    \n",
    "    # initialize -\n",
    "    number_of_iterations = length(fₒ); # how many iterations did we need to converge? \n",
    "    p = pₒ[number_of_iterations - 1]; # this is the probability of the word we want to learn  (0 based)\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "    \n",
    "    ŵ; # return the word we *think* we learned\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8309f2",
   "metadata": {},
   "source": [
    "__Check__: Let's check to see if the recovered image is identical to the original image (not guaranteed). We can do this by checking the `s₁::Array{Float32,1}` variable against the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13cbb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    true_word = test_words[memoryindextorecover]; # this is the word we want to learn\n",
    "    @assert recovered_word_uncorrupted == true_word\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cdd8dd",
   "metadata": {},
   "source": [
    "## Task 3: Retrieve a corrupted memory from the network\n",
    "Fill me in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88dcda",
   "metadata": {},
   "source": [
    "Let's build the corrupted memory. We'll iterate through each embedding dimension from the uncorrupted word; sometimes, we'll make a mistake and replace the correct embedding value with an incorrect value.\n",
    "* _What is the $\\theta$ parameter_? The $\\theta$ hyperparameter controls how often we make mistakes. Its interpretation depends upon our _mistake_ model. For example, if we are cutting off some fraction of the embedding dimension, then $\\theta$ describes the fraction of the image we are cutting off. Alternatively, if we add noise, $1 - \\theta$ describes the fraction of the original image we are keeping.\n",
    "\n",
    "Whichever model we use, the $\\theta\\in[0,1]$. We store the corrupted image in the `s₁::Array{Float64,1}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b286495",
   "metadata": {},
   "outputs": [],
   "source": [
    "s₁ = let\n",
    "\n",
    "    # initialize -\n",
    "    sₒ = mymodel.X[:,memoryindextorecover]; # this is the memory vector we want to recover (uncorrupted)\n",
    "    s₁ = Array{Float32,1}(undef, number_of_embedding_dimesions); # initialize some space to store the corrupted word\n",
    "    θ = 0.65; # threshold (fraction 1 - θ is the fraction the original memory that we retain in model 2)\n",
    "\n",
    "    # Corruption model: Cutoff part of the memory\n",
    "    cutoff = (1-θ)*number_of_embedding_dimesions |> x-> round(Int,x);\n",
    "    for i ∈ 1:number_of_embedding_dimesions\n",
    "        eᵢ =  sₒ[i]; # We have some gray-scale values in the original vector, need to perturb\n",
    "        if (i ≤ cutoff)\n",
    "            s₁[i] = eᵢ;\n",
    "        else\n",
    "            s₁[i] = β*randn(); # add some random noise (proportional to β)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    s₁ # return corrupted data to the calling scope\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b196ef",
   "metadata": {},
   "source": [
    "How different is the corrupted memory from the original (true) memory? Under a squared L2 measure, the distance between the two memories is given by $\\lVert \\mathbf{s}_{\\circ} - \\mathbf{s}_{1}\\rVert_{2}^{2}$. What is this distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf34c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squared L2 norm difference between the corrupted and uncorrupted image is: 24.8718443278219\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    Δ = norm(s₁ - sₒ)^2; # this is the L2 squared difference between the corrupted and uncorrupted memory\n",
    "    println(\"The squared L2 norm difference between the corrupted and uncorrupted image is: $(Δ)\");\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c51f6",
   "metadata": {},
   "source": [
    "Under the squared L2 measure, what is the closest memory to the corrupted memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82be92f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest (using a sq-L2 measure) word to the corrupted memory is: rybarikova\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    # initialize -\n",
    "    X = mymodel.X; # get the training data in the model\n",
    "    Δ = Array{Float64,1}(undef, number_of_words_to_memorize); \n",
    "\n",
    "    for i ∈ 1:number_of_words_to_memorize\n",
    "        sᵢ = X[:,i]; # this is the memory vector we want to recover\n",
    "        Δ[i] = norm(s₁ - sᵢ)^2; # this is the L2 squared difference between the corrupted and uncorrupted memory\n",
    "    end\n",
    "\n",
    "    # compute the most probable word using the L2 measure -\n",
    "    p = NNlib.softmax(Δ); # this is the probability of the word we want to learn\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "\n",
    "    println(\"The closest (using a sq-L2 measure) word to the corrupted memory is: $(ŵ)\");\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455bfb7",
   "metadata": {},
   "source": [
    "What about using the inner product (self attention) measure? The distance between the two memories is given by $\\beta\\cdot\\langle \\mathbf{s}_{\\circ}, \\mathbf{s}_{1}\\rangle$. What is the most probable memory to the corrupted memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6567f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest word (using self-attention socre) to the corrupted memory is: chikka\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    # initialize -\n",
    "    X = mymodel.X; # get the training data in the model\n",
    "    p = β*(transpose(X) * s₁) |> s-> NNlib.softmax(s) # this is the probability of the word we want to learn\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "\n",
    "    # make a table -\n",
    "\n",
    "    println(\"The closest word (using self-attention socre) to the corrupted memory is: $(ŵ)\");\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18945b96",
   "metadata": {},
   "source": [
    "__Do we converge to the correct word starting from corrupted word__? Now that we have a starting (corrupted) memory encoded in the $\\mathbf{s}_{1}$ state vector, can we recover the original uncorrupted memory, i.e., the uncorrputed word? We are guaranteed to converge to a word, but maybe _not_ the correct one.\n",
    "* _Implementation_: We implemented the modern Hopfield recovery algorithm above in [the `recover(...)` method](src/Compute.jl). This method takes our `model::MyModernHopfieldNetworkModel` instance, the initial configuration vector `sₒ::Array{Int32,1}`, and the maximum number `maxiterations::Int64`, and iteration tolerance parameter `ϵ::Float64`. \n",
    "* [The `recover(...)` method](src/Compute.jl) returns the recovered image in the e`s₁::Array{Float32,1}` variable, the image at each iteration in the `f::Dict{Int, Array{Float32,2}}` dictionary, and the probability of the image at each iteration in the `p::Dict{Int, Array{Float32,2}}` variable. The frames and probability dictionaries are indexed from `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99768f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ŝ₁,f₁,p₁) = recover(mymodel, s₁, maxiterations = 10000, ϵ = 1e-16); # iterate until we hit stop condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b880937f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32640870499738117"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p₁[1][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d370391",
   "metadata": {},
   "source": [
    "How many iterations did it take to converge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dac18af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network converged to an answer (staring from a corrupted word) in: 9 iterations.\n"
     ]
    }
   ],
   "source": [
    "println(\"The network converged to an answer (staring from a corrupted word) in: $(length(f₁)) iterations.\") # how many iterations did we need to converge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4ee0b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kaoliang\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recovered_word_corrupted = let \n",
    "    \n",
    "    # initialize -\n",
    "    number_of_iterations = length(f₁); # how many iterations did we need to converge? \n",
    "    p = p₁[number_of_iterations - 1]; # this is the probability of the word we want to learn  (0 based)\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "    \n",
    "    ŵ; # return the word we *think* we recovered\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efc360",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
