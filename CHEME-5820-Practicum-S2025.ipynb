{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad71c3a8-bc41-47c2-bfaa-4757cbceedf2",
   "metadata": {},
   "source": [
    "# Practicum: Modern Hopfield Network Spell Checking and Word Recommendation\n",
    "___\n",
    "In this practicum problem, we'll implement a modern Hopfield Network and use it for spell checking and word recommendation tasks.\n",
    "\n",
    "* _What are Hopfield Networks_? Hopfield Networks are used for associative memory, where the network can recall a pattern from a partial input. The modern version of Hopfield Networks uses continuous values instead of binary values, and it can store multiple patterns. \n",
    "* We'll use the following paper to guide our implementation and analysis: [Ramsauer, H., Schafl, B., Lehner, J., Seidl, P., Widrich, M., Gruber, L., Holzleitner, M., Pavlovi'c, M., Sandve, G.K., Greiff, V., Kreil, D.P., Kopp, M., Klambauer, G., Brandstetter, J., & Hochreiter, S. (2020). Hopfield Networks is All You Need. ArXiv, abs/2008.02217.](https://arxiv.org/abs/2008.02217)\n",
    "\n",
    "## Tasks\n",
    "Before we get started, we'll quickly review modern Hopfied Networks. Then, you'll execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants (5 min)__: Let's take 5 minutes to load [a Simpsons character library from Kaggle](https://www.kaggle.com/datasets/kostastokis/simpsons-faces) that our Hopfield network will memorize.\n",
    "*  __Task 2: Build a Modern Network Model (5 min)__: In this task, we'll formulate the image dataset we give the network and then create a model of a modern Hopfield network. We'll also quickly check to ensure we are doing what we think we are doing.\n",
    "* __Task 3: Retrieve a memory from the network (30 min)__: In this task, we will retrieve a memory from the modern Hopfield network starting from a random state vector $\\mathbf{s}_{\\circ}$. We'll corrupt an image (by cutting off some fraction of the image) and then see if the model recovers the correct memory given the corrupted starting point. \n",
    "\n",
    "Let's get started!\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e0a48",
   "metadata": {},
   "source": [
    "## Background\n",
    "A modern Hopfield network addresses many of the perceived limitations of the original Hopfield network. The original Hopfield network was limited to binary values and could only store a limited number of patterns. The modern Hopfield network uses continuous values and can store a large number of patterns.\n",
    "* For a detailed discussion of the key milestones in the development of modern Hopfield networks, check out [Hopfield Networks is All You Need Blog, GitHub.io](https://ml-jku.github.io/hopfield-layers/)\n",
    "\n",
    "### Algorithm\n",
    "The user provides a set of memory vectors $\\mathbf{X} = \\left\\{\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\ldots, \\mathbf{x}_{m}\\right\\}$, where $\\mathbf{x}_{i} \\in \\mathbb{R}^{n}$ is a memory vector of size $n$ and $m$ is the number of memory vectors. Further, the user provides an initial _partial memory_ $\\mathbf{s}_{\\circ} \\in \\mathbb{R}^{n}$, which is a vector of size $n$ that is a partial version of one of the memory vectors and specifies the _temperature_ $\\beta$ of the system.\n",
    "\n",
    "__Initialize__ the network with the memory vectors $\\mathbf{X}$, and the inverse temperature $\\beta$. Set current state to the initial state $\\mathbf{s} \\gets \\mathbf{s}_{\\circ}$\n",
    "\n",
    "Until convergence __do__:\n",
    "   1. Compute the _current_ probability vector defined as $\\mathbf{p} = \\texttt{softmax}(\\beta\\cdot\\mathbf{X}^{\\top}\\mathbf{s})$ where $\\mathbf{s}$ is the _current_ state vector, and $\\mathbf{X}^{\\top}$ is the transpose of the memory matrix $\\mathbf{X}$.\n",
    "   2. Compute the _next_ state vector $\\mathbf{s}^{\\prime} = \\mathbf{X}\\mathbf{p}$ and the _next_ probability vector $\\mathbf{p}^{\\prime} = \\texttt{softmax}(\\beta\\cdot\\mathbf{X}^{\\top}\\mathbf{s}^{\\prime})$.\n",
    "   3. If $\\mathbf{p}^{\\prime}$ is _close_ to $\\mathbf{p}$ or we run out of iterations, then __stop__. For example, $\\lVert \\mathbf{p}^{\\prime} - \\mathbf{p}\\rVert_{2}^{2} \\leq \\epsilon$ for some small $\\epsilon > 0$.\n",
    "   4. Otherwise, update the state $\\mathbf{s} \\gets\\mathbf{s}^{\\prime}$, and __go back to__ step 1.\n",
    "\n",
    "   \n",
    "This algorithm is implemented in [the `recover(...)` method](src/Compute.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b935753",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184b2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\"); # load a bunch of libs, including the ones we need to work with images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aba20e",
   "metadata": {},
   "source": [
    "### Constants\n",
    "Before we load the data, let's set up some constants that we will use in the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f255b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_words_to_memorize = 24; # how many images do we want to memorize?\n",
    "number_of_embedding_dimesions = 50; # number of embedding dimensions for each word\n",
    "β = 1.5; # Inverse temperature of the system (high T -> low β)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99cc6c7",
   "metadata": {},
   "source": [
    "### Data\n",
    "We'll use the [GloVe pretrained word embedding dataset](https://nlp.stanford.edu/projects/glove/) to as the memories for our Hopfield model. The **GloVe (Global Vectors for Word Representation)** dataset is a widely used pre-trained word embedding resource developed by Pennington, Socher, and Manning at Stanford University. \n",
    "* _What is it?_ It constructs vector representations of words by aggregating global word co-occurrence statistics from a corpus, enabling semantic relationships to be captured in vector space. GloVe embeddings have been trained on large datasets such as Wikipedia, Gigaword, and Common Crawl, offering dimensionalities typically ranging from 50 to 300. These embeddings are foundational for many NLP tasks, including text classification, sentiment analysis, and machine translation.\n",
    "* See: [Pennington et al., EMNLP 2014, GloVe: Global Vectors for Word Representation](https://aclanthology.org/D14-1162/) for more details on this dataset.\n",
    "\n",
    "This dataset is large, so we won't check it into the repository. Instead, we'll download it from the internet. Fill me in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34627ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec, vec2word = let\n",
    "\n",
    "    # do we have the embeddings downloaded?\n",
    "    data = nothing;\n",
    "    if (isfile(joinpath(_PATH_TO_DATA, \"glove_6B_50d.jld2\")) == false) \n",
    "        # TODO: download logic goes here ...\n",
    "    else\n",
    "        data = JLD2.load(joinpath(_PATH_TO_DATA, \"glove_6B_50d.jld2\")) # Ok, we have the embeddings file, so let's load it\n",
    "    end\n",
    "\n",
    "    # load the embeddings\n",
    "    word2vec = data[\"word2vec\"] # this is a Dict{String, Tuple{Float32}}\n",
    "    vec2word = data[\"vec2word\"] # this is a Dict{Tuple{Float32}, String}\n",
    "\n",
    "    # return -\n",
    "    (word2vec, vec2word)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b6cd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, NTuple{50, Float64}} with 400000 entries:\n",
       "  \"newdigate\"   => (-0.13302, 0.99457, 0.19927, 0.062554, 0.40293, 0.58369, 0.1…\n",
       "  \"daufuskie\"   => (0.47702, -0.33101, -1.0066, 0.70388, -0.29973, -0.54381, -0…\n",
       "  \"single-arm\"  => (0.7153, 0.67314, 1.6732, 0.21066, 1.1875, 2.3162, 0.078471,…\n",
       "  \"titration\"   => (0.30649, -0.66054, -0.27341, -0.30447, -0.58893, 0.64415, 1…\n",
       "  \"qajar\"       => (-1.2141, -0.039392, -0.63721, 0.058088, -0.22625, -1.0897, …\n",
       "  \"pinheiro\"    => (0.49711, -0.31449, -1.0776, 0.61769, 0.066749, -2.1997, 0.0…\n",
       "  \"hospitalet\"  => (-0.55697, 0.19924, -1.099, -0.92013, -1.1645, -0.45907, 0.7…\n",
       "  \"kennedale\"   => (-0.91243, -0.097526, 0.031527, 0.71883, -0.89733, -1.0061, …\n",
       "  \"tetracyclic\" => (0.49991, -0.98145, 0.01992, -0.88848, 0.24377, 0.27405, 0.8…\n",
       "  \"moher\"       => (0.097974, 0.99096, -0.63521, 0.49702, 0.043669, 0.035202, 0…\n",
       "  \"entomb\"      => (0.64585, -0.28799, 0.59975, -0.43203, -0.64485, 0.11591, -0…\n",
       "  \"vanderwerff\" => (-1.0542, -0.47031, -1.4568, 0.93613, 0.062686, 1.5889, -0.6…\n",
       "  \"whiz\"        => (-0.93844, -0.15695, 1.0516, -0.47339, -0.58016, -0.85521, -…\n",
       "  \"hi5\"         => (0.23578, -0.045139, 0.79017, 0.23509, -0.68271, 0.39011, -0…\n",
       "  \"johnswort\"   => (0.75264, 0.51297, -0.093784, -1.1576, -0.018352, -0.91108, …\n",
       "  \"11-storey\"   => (0.036837, -0.076804, 0.6941, -0.92608, 1.4386, -0.078356, 0…\n",
       "  \"clapboards\"  => (-0.73615, 0.068203, 0.28849, -0.44785, -0.96452, 0.87112, -…\n",
       "  \"saïd\"        => (-1.3314, -0.13012, 0.37243, -0.18406, -0.056918, -1.2969, 0…\n",
       "  \"nóg\"         => (-0.88271, -0.35731, 0.3633, 0.45749, -1.5215, -0.14872, 1.1…\n",
       "  ⋮             => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0221159d",
   "metadata": {},
   "source": [
    "Fill me in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c94374",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words, test_vocabulary = let\n",
    "\n",
    "    # initialize -\n",
    "    vocabulary = Array{Float64,2}(undef, number_of_words_to_memorize, number_of_embedding_dimesions); # this is a matrix of Float64\n",
    "    test_words = Array{String,1}(undef, number_of_words_to_memorize); # this is a vector of strings\n",
    "    total_number_of_words = length(word2vec); # this is the total number of words in the dataset\n",
    "    index_of_words_to_learn = randperm(total_number_of_words)[1:number_of_words_to_memorize]; # this is the random index of words to learn\n",
    "\n",
    "    # get the keys of word2vec -\n",
    "    words = keys(word2vec) |> collect; # this is a vector of strings\n",
    "\n",
    "    # loop over the words to learn\n",
    "    for i ∈ eachindex(index_of_words_to_learn)\n",
    "        \n",
    "        j = index_of_words_to_learn[i]; # this is the index of the word we want to learn\n",
    "        wⱼ = words[j]; # this is the word we want to learn\n",
    "        test_words[i] = wⱼ; # this is the word we want to learn \n",
    "        embedding = word2vec[wⱼ]; # this is the embedding of the word we want to learn\n",
    "\n",
    "        for j ∈ 1:number_of_embedding_dimesions\n",
    "            vocabulary[i,j] = embedding[j]; # this is the embedding of the word we want to learn\n",
    "        end\n",
    "    end\n",
    "\n",
    "    test_vocabulary = vocabulary |> transpose |> Matrix; # this is the vocabulary we want to learn\n",
    "\n",
    "    # return -\n",
    "    (test_words, test_vocabulary);\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc729cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24-element Vector{String}:\n",
       " \"klingenthal\"\n",
       " \"riedelsheimer\"\n",
       " \"newpaper\"\n",
       " \"vixen\"\n",
       " \"botticelli\"\n",
       " \"mtbe\"\n",
       " \"bodian\"\n",
       " \"thiocyanate\"\n",
       " \"riles\"\n",
       " \"strad\"\n",
       " ⋮\n",
       " \"klitschkos\"\n",
       " \"dustup\"\n",
       " \"activités\"\n",
       " \"rybarikova\"\n",
       " \"2125\"\n",
       " \"sippola\"\n",
       " \"3634\"\n",
       " \"arimori\"\n",
       " \"58-58\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccd492",
   "metadata": {},
   "source": [
    "__Let's do some fun stuff with embeddings.__ Fill me in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ddd93",
   "metadata": {},
   "source": [
    "## Task 2: Can we recover an uncorrupted memory?\n",
    "In this task, we'll formulate the set of word embeddings (memories) that we feed to a modern Hopfield network. First, we'll create a modern Hopfield network model, and then we'll use the model to retrieve a memory from the network. We'll do this by starting from a random state vector $\\mathbf{s}_{\\circ}$, which is a partial version of one of the memory vectors, i.e., a misspled word. We'll corrupt the word by randomly permuating it's embeddings, and then we'll see if the model recovers the correct word (memory) given the corrupted starting point.\n",
    "\n",
    "### Model\n",
    "Let's start by creating a model of a modern Hopfield network. \n",
    "* We'll construct [a `MyModernHopfieldNetworkModel` instance](src/Types.jl) using a custom [`build(...)` function](src/Factory.jl). The [`build(...)` method](src/Factory.jl) takes the type of thing we want to build, the (linearized) image library we want to encode, and the (inverse) system temperature $\\beta$ as inputs — images along the columns.\n",
    "* The [`build(...)` function](src/Factory.jl) returns a `MyModernHopfieldNetworkModel` instance, where the image library is stored in the `X::Array{Float64,2}` field, and the system temperature is stored in the `β::Float64` field.\n",
    "\n",
    "We'll store the Hopfield network instance in the `mymodel::MyModernHopfieldNetworkModel` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b88f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = let\n",
    "\n",
    "    # initialize -\n",
    "    memorycollection =test_vocabulary; # words (memories) on columns\n",
    "    index_vector = 1:number_of_words_to_memorize |> collect; # this is the index of the words we want to learn\n",
    "    words = keys(test_vocabulary) |> collect; # this is a vector of strings\n",
    "    \n",
    "    # build model -\n",
    "    model = build(MyModernHopfieldNetworkModel, (\n",
    "            memories = memorycollection, # this is the data we want to memorize. Images on columns\n",
    "            β = β, # Inverse temperature of the system. A big beta means we are more likely to get the right answer\n",
    "    ));\n",
    "\n",
    "    model; # return the model to the calling scope\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b18b75",
   "metadata": {},
   "source": [
    "__Check__: Let's do a quick check to make sure we are doing what we think we are doing. Let's check what's stored in the columns of the `model.X` field. These should be the words that we are encoding into the Hopfield network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8905f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word at index 18 that we encoded is: activités. The word from vec2word is: activités\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    \n",
    "    X = mymodel.X; # get the training data in the model\n",
    "    index_to_check = rand(1:number_of_words_to_memorize); # what index do we want to check?\n",
    "    \n",
    "    \n",
    "    eᵢ = X[:,index_to_check] |> Tuple # this is the embedding of the word we want to learn\n",
    "    wᵢ = test_words[index_to_check]; # this is the word we want to learn\n",
    "    ŵᵢ = vec2word[eᵢ]; # this is the word we think we learned\n",
    "\n",
    "    println(\"The word at index $(index_to_check) that we encoded is: $(wᵢ). The word from vec2word is: \", ŵᵢ);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cf809",
   "metadata": {},
   "source": [
    "### Retrieve a memory from the network\n",
    "Next, we'll test if we can recover uncorrupted and corrupted memories from the Hopfield network.\n",
    "\n",
    "* _What should we expect_: We are _guaranteed_ that the network will converge to a local minimum, but we are not guaranteed that the local minimum is the same as the original image. \n",
    "\n",
    "Let's start by specifying which memory we are trying to recover in the `memoryindextorecover::Int` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93d68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryindextorecover = 15; # which memory vector will we choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac193276",
   "metadata": {},
   "source": [
    "Next, let's build an uncorrupted and corrupted initial condition vector using the true word emebedding vector. We'll store \n",
    "the uncorrupted word in the `sₒ::Array{Float64,1}` variable, while the corrupted word will be stored in the `s₁::Array{Float64,1}` variable. Let's start with the uncorrupted memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5184ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sₒ = mymodel.X[:,memoryindextorecover]; # this is the memory vector we want to recover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92773242",
   "metadata": {},
   "source": [
    "What word does `memoryindextorecover::Int64` point to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac7067c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word at index 15 that we (think) we encoded is: chikka. Check: the true word is: chikka\n"
     ]
    }
   ],
   "source": [
    "let \n",
    "    X = mymodel.X; # get the training data in the model\n",
    "    p = β*(transpose(X) * sₒ) |> s-> NNlib.softmax(s) # this is the probability of the word we want to learn\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "    w = test_words[memoryindextorecover]; # this is the word we want to learn\n",
    "    println(\"The word at index $(memoryindextorecover) that we (think) we encoded is: $(ŵ). Check: the true word is: \", w);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558716a",
   "metadata": {},
   "source": [
    "Now that we have a starting memory encoded in the state vector $\\mathbf{s}_{\\circ}$, can we recover the original uncorrupted word? We are guaranteed an image, but maybe _not_ the correct one.\n",
    "* _Implementation_: We implemented the modern Hopfield recovery algorithm above in [the `recover(...)` method](src/Compute.jl). This method takes our `model::MyModernHopfieldNetworkModel` instance, the initial configuration vector `sₒ::Array{Int32,1}`, and the maximum number `maxiterations::Int64`, and iteration tolerance parameter `ϵ::Float64`. \n",
    "* [The `recover(...)` method](src/Compute.jl) returns the recovered image in the e`s₁::Array{Float32,1}` variable, the image at each iteration in the `f::Dict{Int, Array{Float32,2}}` dictionary, and the probability of the image at each iteration in the `p::Dict{Int, Array{Float32,2}}` variable. The frames and probability dictionaries are indexed from `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3049a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ŝₒ,fₒ,pₒ) = recover(mymodel, sₒ, maxiterations = 10000, ϵ = 1e-16); # iterate until we hit stop condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b18c41",
   "metadata": {},
   "source": [
    "How many iterations did it take to converge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d6ef339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations: 3\n"
     ]
    }
   ],
   "source": [
    "println(\"How many iterations: $(length(fₒ))\") # how many iterations did we need to converge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a404ed",
   "metadata": {},
   "source": [
    "Fill me in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29818778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"chikka\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recovered_word_uncorrupted = let \n",
    "    \n",
    "    # initialize -\n",
    "    number_of_iterations = length(fₒ); # how many iterations did we need to converge? \n",
    "    p = pₒ[number_of_iterations - 1]; # this is the probability of the word we want to learn  (0 based)\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "    \n",
    "    ŵ; # return the word we *think* we learned\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8309f2",
   "metadata": {},
   "source": [
    "__Check__: Let's check to see if the recovered image is identical to the original image (not guaranteed). We can do this by checking the `s₁::Array{Float32,1}` variable against the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13cbb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    true_word = test_words[memoryindextorecover]; # this is the word we want to learn\n",
    "    @assert recovered_word_uncorrupted == true_word\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cdd8dd",
   "metadata": {},
   "source": [
    "## Task 3: Retrieve a corrupted memory from the network\n",
    "Fill me in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88dcda",
   "metadata": {},
   "source": [
    "Let's build the corrupted memory. We'll iterate through each embedding dimension from the uncorrupted word; sometimes, we'll make a mistake and replace the correct embedding value with an incorrect value.\n",
    "* _What is the $\\theta$ parameter_? The $\\theta$ hyperparameter controls how often we make mistakes. Its interpretation depends upon our _mistake_ model. For example, if we are cutting off some fraction of the embedding dimension, then $\\theta$ describes the fraction of the image we are cutting off. Alternatively, if we add noise, $1 - \\theta$ describes the fraction of the original image we are keeping.\n",
    "\n",
    "Whichever model we use, the $\\theta\\in[0,1]$. We store the corrupted image in the `s₁::Array{Float64,1}` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b286495",
   "metadata": {},
   "outputs": [],
   "source": [
    "s₁ = let\n",
    "\n",
    "    # initialize -\n",
    "    sₒ = mymodel.X[:,memoryindextorecover]; # this is the memory vector we want to recover (uncorrupted)\n",
    "    s₁ = Array{Float32,1}(undef, number_of_embedding_dimesions); # initialize some space to store the corrupted word\n",
    "    θ = 0.5; # threshold (fraction 1 - θ is the fraction the original memory that we retain in model 2)\n",
    "\n",
    "    # Model 1: Add random noise to the test image\n",
    "    # for i ∈ 1:number_of_pixels\n",
    "    #     pixel =  ŝₖ[i]; # We have some gray-scale values in the original vector, need to perturb\n",
    "    #     if (rand() ≤ θ)\n",
    "    #         sₒ[i] = rand(); # add some random noise\n",
    "    #     else\n",
    "    #         sₒ[i] = pixel;\n",
    "    #     end\n",
    "    # end\n",
    "\n",
    "    # Model 2: Cutoff part of the image\n",
    "    cutoff = (1-θ)*number_of_embedding_dimesions |> x-> round(Int,x);\n",
    "    for i ∈ 1:number_of_embedding_dimesions\n",
    "        eᵢ =  sₒ[i]; # We have some gray-scale values in the original vector, need to perturb\n",
    "        if (i ≤ cutoff)\n",
    "            s₁[i] = eᵢ;\n",
    "        else\n",
    "            s₁[i] = β*randn(); # add some random noise\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    s₁ # return corrupted data to the calling scope\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b196ef",
   "metadata": {},
   "source": [
    "How different is the corrupted memory from the original (true) memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf34c1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squared norm difference between the corrupted and uncorrupted image is: 78.69274175003395\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    Δ = norm(s₁ - sₒ)^2; # this is the L2 squared difference between the corrupted and uncorrupted memory\n",
    "    println(\"The squared norm difference between the corrupted and uncorrupted image is: $(Δ)\");\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18945b96",
   "metadata": {},
   "source": [
    "Now that we have a starting (corrupted) memory encoded in the $\\mathbf{s}_{1}$ state vector, can we recover the original uncorrupted memory, i.e., the uncorrputed word? We are guaranteed to converge to a word, but maybe _not_ the correct one.\n",
    "* _Implementation_: We implemented the modern Hopfield recovery algorithm above in [the `recover(...)` method](src/Compute.jl). This method takes our `model::MyModernHopfieldNetworkModel` instance, the initial configuration vector `sₒ::Array{Int32,1}`, and the maximum number `maxiterations::Int64`, and iteration tolerance parameter `ϵ::Float64`. \n",
    "* [The `recover(...)` method](src/Compute.jl) returns the recovered image in the e`s₁::Array{Float32,1}` variable, the image at each iteration in the `f::Dict{Int, Array{Float32,2}}` dictionary, and the probability of the image at each iteration in the `p::Dict{Int, Array{Float32,2}}` variable. The frames and probability dictionaries are indexed from `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99768f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ŝ₁,f₁,p₁) = recover(mymodel, s₁, maxiterations = 10000, ϵ = 1e-16); # iterate until we hit stop condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d370391",
   "metadata": {},
   "source": [
    "How many iterations did it take to converge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dac18af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations: 5\n"
     ]
    }
   ],
   "source": [
    "println(\"How many iterations: $(length(f₁))\") # how many iterations did we need to converge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee0b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"chikka\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recovered_word_corrupted = let \n",
    "    \n",
    "    # initialize -\n",
    "    number_of_iterations = length(f₁); # how many iterations did we need to converge? \n",
    "    p = p₁[number_of_iterations - 1]; # this is the probability of the word we want to learn  (0 based)\n",
    "    ŵ = argmax(p) |> i-> test_words[i]; # this is the index of the word we think we learned\n",
    "    \n",
    "    ŵ; # return the word we *think* we recovered\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efc360",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
